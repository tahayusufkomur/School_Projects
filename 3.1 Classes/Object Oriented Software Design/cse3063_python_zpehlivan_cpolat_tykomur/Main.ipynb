{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fa68aa048b55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;34m'-ea'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;34mf'-Djava.class.path={ZEMBEREK_PATH}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mconvertStrings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/jpype/_core.py\u001b[0m in \u001b[0;36mstartJVM\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m      \"\"\"\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_jpype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misStarted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'JVM is already started'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_JVM_started\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_JVM_started\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: JVM is already started"
     ],
     "ename": "OSError",
     "evalue": "JVM is already started",
     "output_type": "error"
    }
   ],
   "source": [
    "import errno\n",
    "import glob\n",
    "from os.path import join\n",
    "from typing import List\n",
    "from jpype import JClass, getDefaultJVMPath, shutdownJVM, startJVM, java\n",
    "import Generator as gnr\n",
    "from Word import Word\n",
    "\n",
    "path = 'data/1150haber/*.txt'\n",
    "files = glob.glob(path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    ZEMBEREK_PATH: str = join(\"/Users/tahayusufkomur/PycharmProjects/word_generate/bin/zemberek-full.jar\")\n",
    "\n",
    "    startJVM(\n",
    "        getDefaultJVMPath(),\n",
    "        '-ea',\n",
    "        f'-Djava.class.path={ZEMBEREK_PATH}',\n",
    "        convertStrings=False\n",
    "    )\n",
    "\n",
    "    TurkishSentenceExtractor: JClass = JClass(\n",
    "        'zemberek.tokenization.TurkishSentenceExtractor'\n",
    "    )\n",
    "\n",
    "    extractor: TurkishSentenceExtractor = TurkishSentenceExtractor.DEFAULT\n",
    "\n",
    "    TurkishMorphology: JClass = JClass('zemberek.morphology.TurkishMorphology')\n",
    "\n",
    "    morphology: TurkishMorphology = TurkishMorphology.createWithDefaults()\n",
    "\n",
    "Nouns = []\n",
    "Adjectives = []\n",
    "Verbs = []\n",
    "Conjunctions = []\n",
    "PostPositives = []\n",
    "all_words = []\n",
    "\n",
    "\"\"\"\"\"\n",
    "We reading all files here and distributing them to 5 different lists depends on their pos'es\n",
    "\"\"\"\"\"\n",
    "for name in files:\n",
    "    try:\n",
    "        with open(name) as f:\n",
    "            sentences = extractor.fromParagraph(f.read())\n",
    "            for i, word in enumerate(sentences):\n",
    "                x = f'{word}'\n",
    "                sentence: str = x\n",
    "                analysis: java.util.ArrayList = (\n",
    "                    morphology.analyzeAndDisambiguate(sentence).bestAnalysis()\n",
    "                )\n",
    "                pos: List[str] = []\n",
    "\n",
    "                for i, analysis in enumerate(analysis, start=1):\n",
    "                    if f'{analysis.getPos()}' != \"Punctuation\":\n",
    "                        x = f'{analysis}'\n",
    "                        p = x.find(':')  # cleaning data\n",
    "                        x = x[1:p]  # cleaning data\n",
    "                        all_words.append(Word(x, gnr.get_weight(x), f'{analysis.getPos()}'))  # all_words\n",
    "                        if f'{analysis.getPos()}' == 'Noun':\n",
    "                            Nouns.append(Word(x, gnr.get_weight(x), f'{analysis.getPos()}'))  # Nouns\n",
    "                        if f'{analysis.getPos()}' == 'Verb':\n",
    "                            Verbs.append(Word(x, gnr.get_weight(x), f'{analysis.getPos()}'))  # Verbs\n",
    "                        if f'{analysis.getPos()}' == 'Conjunction':\n",
    "                            Conjunctions.append(Word(x, gnr.get_weight(x), f'{analysis.getPos()}'))  # Conjunctions\n",
    "                        if f'{analysis.getPos()}' == 'PostPositive':\n",
    "                            PostPositives.append(Word(x, gnr.get_weight(x), f'{analysis.getPos()}'))  # PostPositives\n",
    "                        if f'{analysis.getPos()}' == 'Adjective':\n",
    "                            Adjectives.append(Word(x, gnr.get_weight(x), f'{analysis.getPos()}'))  # Adjectives\n",
    "                        else:\n",
    "                            continue\n",
    "    except IOError as exc:\n",
    "        if exc.errno != errno.EISDIR:\n",
    "            raise\n",
    "\n",
    "w_sentences = gnr.generate_sentences(30, 1000, Nouns, Verbs, Adjectives, Conjunctions, PostPositives)\n",
    "for i in w_sentences:\n",
    "    print('weight -> ', i.lentgth_of_sentence(), ' ', end='')\n",
    "    w = i.words\n",
    "    for t in w:\n",
    "        print(t.name, ' ', end='')\n",
    "    print('')\n",
    "\n",
    "w_words = gnr.generate_random_weighted_words(all_words, 25, 100)\n",
    "for i in w_words:\n",
    "    print(i.name, ' ', i.weight)\n",
    "\n",
    "shutdownJVM()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}