{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mjava.lang.NoClassDefFoundError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e03181a7e197>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     )\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mTurkishMorphology\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mJClass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'zemberek.morphology.TurkishMorphology'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mPaths\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mJClass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.nio.file.Paths'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/jpype/_jclass.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_JClassNew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/jpype/_jclass.py\u001b[0m in \u001b[0;36m_JClassNew\u001b[0;34m(arg, loader, initialize)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mjavaClass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mjavaClass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_jpype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyJPClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mjavaClass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mjava.lang.NoClassDefFoundError\u001b[0m: zemberek/morphology/TurkishMorphology"
     ],
     "ename": "java.lang.NoClassDefFoundError",
     "evalue": "zemberek/morphology/TurkishMorphology",
     "output_type": "error"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random as rnd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from os.path import join\n",
    "from jpype import JClass, getDefaultJVMPath, java, shutdownJVM, startJVM\n",
    "import nltk.data\n",
    "import codecs\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    ZEMBEREK_PATH: str = join('..', '..', 'bin', 'zemberek-full.jar')\n",
    "\n",
    "    startJVM(\n",
    "            getDefaultJVMPath(),\n",
    "            '-ea',\n",
    "            f'-Djava.class.path={\"C://Users//ASUS//Desktop//cz//distributions//0.17.1//zemberek-full.jar\"}',\n",
    "            convertStrings=False\n",
    "    )\n",
    "   \n",
    "    TurkishMorphology: JClass = JClass('zemberek.morphology.TurkishMorphology')\n",
    "    Paths: JClass = JClass('java.nio.file.Paths')\n",
    "\n",
    "    morphology: TurkishMorphology = TurkishMorphology.createWithDefaults()\n",
    "\n",
    "path = \"C://Users//ASUS//Desktop//cz//1150haberAZ\"\n",
    "fileNames = []\n",
    "wordList = []\n",
    "\n",
    "fileNames = [ subdir+os.path.sep+file for subdir, dirs, files in os.walk(path) for file in files ]\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(decode_error='ignore')\n",
    "docTermMatrix = tfidfVectorizer.fit_transform((open(f,encoding=\"utf8\").read() for f in fileNames))\n",
    "\n",
    "wordList = [ word[0] for word in tfidfVectorizer.vocabulary_.items() ]\n",
    "verb_list = []\n",
    "\n",
    "for f in fileNames:\n",
    "    doc = codecs.open(f, 'r', 'utf-8')\n",
    "    content = doc.read()\n",
    "\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/turkish.pickle')\n",
    "    tokenized_sentence = tokenizer.tokenize(content)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "from os.path import join\n",
    "from jpype import JClass, JString, getDefaultJVMPath, java, shutdownJVM, startJVM\n",
    "\n",
    "\n",
    "def find_synonyms(sentence):   \n",
    "    global new_sentence\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "#     print(\"ORIGINAL SENTENCE: \" + sentence)\n",
    "    return_sentence = \"\"\n",
    "    sentence_words = []\n",
    "    sentence_for_synonym_search = []\n",
    "    \n",
    "    if __name__ == '__main__':\n",
    "\n",
    "        ZEMBEREK_PATH: str = join('..', '..', 'bin', 'zemberek-full.jar')\n",
    "\n",
    "        TurkishMorphology: JClass = JClass('zemberek.morphology.TurkishMorphology')\n",
    "        Paths: JClass = JClass('java.nio.file.Paths')\n",
    "\n",
    "        morphology: TurkishMorphology = TurkishMorphology.createWithDefaults()\n",
    "    \n",
    "    for i in sentence.split():\n",
    "        sentence: str = i\n",
    "        analysis: java.util.ArrayList = morphology.analyzeSentence(sentence)\n",
    "\n",
    "        results: java.util.ArrayList = (\n",
    "            morphology.disambiguate(sentence, analysis).bestAnalysis()\n",
    "        )\n",
    "        \n",
    "        #add sentence just subject, adjective, noun and verb from original sentence\n",
    "        for j, result in enumerate(results, start=0):\n",
    "            x = (str(result)).split(\":\")[1]\n",
    "            y = x.split(\"]\")[0]\n",
    "            if y == \"Pron,Pers\": #Select Subject Data\n",
    "                x = (str(result)).split(\":\")[0]\n",
    "                y = x.split(\"[\")[1]\n",
    "                sentence_for_synonym_search.append(y)\n",
    "            elif y == \"Adj\": #Select Adj Data\n",
    "                x = (str(result)).split(\":\")[0]\n",
    "                y = x.split(\"[\")[1]\n",
    "                sentence_words.append(sentence.split()[j])\n",
    "                sentence_for_synonym_search.append(y)\n",
    "            elif y == \"Noun\": #Select Noun Data\n",
    "                x = (str(result)).split(\":\")[0]\n",
    "                y = x.split(\"[\")[1]\n",
    "                sentence_words.append(sentence.split()[j])\n",
    "                sentence_for_synonym_search.append(y)\n",
    "            elif y == \"Verb\": #Select Verb Data\n",
    "                x = (str(result)).split(\":\")[0]\n",
    "                y = x.split(\"[\")[1]\n",
    "                sentence_words.append(sentence.split()[j])\n",
    "                sentence_for_synonym_search.append(y)\n",
    "\n",
    "    word_new = \"\"\n",
    "    \n",
    "    for kelime,original_word in zip(sentence_for_synonym_search,sentence_words):\n",
    "        kelime_new = kelime.replace('ö','o')\n",
    "        kelime_new = kelime_new.replace('ı','i')\n",
    "        kelime_new = kelime_new.replace('ü','u')\n",
    "        kelime_new = kelime_new.replace('ç','c')\n",
    "        kelime_new = kelime_new.replace('ş','s')\n",
    "        kelime_new = kelime_new.replace('ğ','g')\n",
    "        kelime_new = kelime_new.strip()\n",
    "#         print(\"KELIME_NEW: \" + kelime_new)\n",
    "        #find synonyms from site\n",
    "#         try:\n",
    "\n",
    "        if kelime not in verb_list:\n",
    "            user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
    "\n",
    "            url = \"http://www.es-anlam.com/kelime/\" + kelime_new\n",
    "            headers={'User-Agent':user_agent,} \n",
    "\n",
    "            request=urllib.request.Request(url,None,headers) #The assembled request\n",
    "            response = urllib.request.urlopen(request)\n",
    "            soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "            ana = soup.find('h2')\n",
    "            alt=ana.find('strong')\n",
    "            alt = str(alt)\n",
    "            alt = (alt.split(\">\")[1]).split(\",\")[0]\n",
    "            alt = alt.split(\"<\")[0]\n",
    "            alt = alt.strip()\n",
    "\n",
    "            if alt == \"BULUNAMADI !\":\n",
    "                new_sentence = new_sentence + \" \" + original_word\n",
    "            else:\n",
    "#                 new_sentence = new_sentence + \" \" + alt\n",
    "                word_new = alt\n",
    "\n",
    "                add_suffix(original_word, word_new)   \n",
    "#             print(\"NEW_SENTENCE IF: \" + new_sentence)\n",
    "    \n",
    "        else:\n",
    "            new_sentence += \" \" + original_word\n",
    "#             print(\"NEW_SENTENCE ELSE: \" + new_sentence)\n",
    "\n",
    "    return new_sentence\n",
    "    \n",
    "\n",
    "def add_suffix(sentence_word, synonym_word):\n",
    "    global new_sentence\n",
    "    TurkishMorphology: JClass = JClass('zemberek.morphology.TurkishMorphology')\n",
    "    WordAnalysis: JClass = JClass('zemberek.morphology.analysis.WordAnalysis')\n",
    "\n",
    "    morphology: TurkishMorphology = TurkishMorphology.createWithDefaults()\n",
    "    \n",
    "    results: WordAnalysis = morphology.analyze(JString(sentence_word))\n",
    "\n",
    "    number = \"\"\n",
    "    possessive = \"\"\n",
    "    case = \"\"\n",
    "    word = \"\"\n",
    "\n",
    "    for result in results:\n",
    "        result = str(result)\n",
    "        try:#set number\n",
    "            if \"A3sg\" in result:\n",
    "                number = \"A3sg\"\n",
    "            elif \"A3pl\" in result:\n",
    "                number = \"A3pl\"\n",
    "        except:\n",
    "            number = \"\"\n",
    "        \n",
    "        try: #set possessive\n",
    "            if \"P1sg\" in result:\n",
    "                possessive =\"P1sg\"\n",
    "            elif \"P2sg\" in results:\n",
    "                possessive = \"P2sg\"\n",
    "            elif \"P3sg\" in result:\n",
    "                possessive = \"P3sg\"\n",
    "        except:\n",
    "            possessive = \"\"\n",
    "        \n",
    "        try: #set case\n",
    "            if \"Dat\" in result:\n",
    "                case = \"Dat\"\n",
    "            elif \"Loc\" in result:\n",
    "                case = \"Loc\"\n",
    "            elif \"Abl\" in result:\n",
    "                case = \"Abl\"\n",
    "        except:\n",
    "            case = \"\"   #cases: List[JString] = [JString('Dat'), JString('Loc'), JString('Abl')]\n",
    "        \n",
    "        word = result.split(\" \")[1]\n",
    "        word = word.split(\":\")[0]\n",
    "\n",
    "    morphology: TurkishMorphology = (\n",
    "        TurkishMorphology.builder().setLexicon(synonym_word).disableCache().build()\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        item = morphology.getLexicon().getMatchingItems(synonym_word).get(0)\n",
    "\n",
    "        if number != \"\" and possessive != \"\" and case != \"\":\n",
    "            for result in morphology.getWordGenerator().generate(item, number, possessive, case):\n",
    "                new_sentence += \" \" + str(result.surface)\n",
    "        elif number != \"\" and possessive != \"\" and case == \"\":\n",
    "             for result in morphology.getWordGenerator().generate(item, number, possessive):\n",
    "                new_sentence += \" \" + str(result.surface)\n",
    "        elif number != \"\" and possessive == \"\" and case != \"\":\n",
    "             for result in morphology.getWordGenerator().generate(item, number, case):\n",
    "                new_sentence += \" \" + str(result.surface)\n",
    "        elif number == \"\" and possessive != \"\" and case != \"\":\n",
    "             for result in morphology.getWordGenerator().generate(item, possessive, case):\n",
    "                new_sentence += \" \" + str(result.surface)\n",
    "        elif number == \"\" and possessive == \"\" and case != \"\":\n",
    "             for result in morphology.getWordGenerator().generate(item, case):\n",
    "                new_sentence += \" \" + str(result.surface)\n",
    "        elif number == \"\" and possessive != \"\" and case == \"\":\n",
    "             for result in morphology.getWordGenerator().generate(item, possessive):\n",
    "                new_sentence += \" \" + str(result.surface)\n",
    "        elif number != \"\" and possessive == \"\" and case == \"\":\n",
    "             for result in morphology.getWordGenerator().generate(item, number):\n",
    "                new_sentence += \" \" + str(result.surface)\n",
    "        else:\n",
    "            new_sentence += str(result.surface)\n",
    "    except:\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def valueList(word_list):\n",
    "    \n",
    "    letterValue = {'a':1, 'b':2, 'c':3, 'ç':4, 'd':5, 'e':6, 'f':7, 'g':8, 'ğ':9, 'h':10, 'ı':11,\n",
    "                 'i':12, 'j':13, 'k':14, 'l':15, 'm':16, 'n':17, 'o':18, 'ö':19, 'p':20, 'r':21,\n",
    "                 's':22, 'ş':23, 't':24, 'u':25, 'ü':26, 'v':27, 'y':28, 'z':29 }\n",
    "    values = []\n",
    "    \n",
    "    for word in word_list:\n",
    "        total = 0      \n",
    "        for letter in word:\n",
    "            if letter not in letterValue:\n",
    "                continue\n",
    "            total = total + letterValue[letter]\n",
    "            \n",
    "        values.append(total)\n",
    "\n",
    "    return values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4a1853ae035b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mgenerate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mshutdownJVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-4a1853ae035b>\u001b[0m in \u001b[0;36mgenerate_sentence\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msentence_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m600\u001b[0m \u001b[0;31m#SENTENCE VALUE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwordList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0manalysis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjava\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArrayList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmorphology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzeSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wordList' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'wordList' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "new_sentence = \"\" #global sentence for generating new sentence\n",
    "\n",
    "def generate_sentence():\n",
    "    global verb_list\n",
    "    global new_sentence\n",
    "    sentence_sum = 600 #SENTENCE VALUE\n",
    "    \n",
    "    for i in wordList:\n",
    "        sentence: str = i\n",
    "        analysis: java.util.ArrayList = morphology.analyzeSentence(sentence)\n",
    "\n",
    "        results: java.util.ArrayList = (\n",
    "            morphology.disambiguate(sentence, analysis).bestAnalysis()\n",
    "        )\n",
    "        \n",
    "        for j, result in enumerate(results, start=0):\n",
    "            x = (str(result)).split(\":\")[1]\n",
    "            y = x.split(\"]\")[0]\n",
    "\n",
    "            if y == \"Verb\": #Select Verb Data\n",
    "                x = (str(result)).split(\":\")[0]\n",
    "                y = x.split(\"[\")[1]\n",
    "                verb_list.append(y)\n",
    "                verb_list = list(dict.fromkeys(verb_list))\n",
    "\n",
    "    gen_sentence_list = []\n",
    "    sentence_value = 0\n",
    "    cntrl = 0\n",
    "\n",
    "    print(\"GENERATING SENTENCE, PLEASE WAIT...\")\n",
    "    for sentence in tokenized_sentence:\n",
    "        if cntrl == 1:\n",
    "            new_sentence = \"\"\n",
    "        synonym_sentence = \"\"\n",
    "        synonym_sentence = find_synonyms(sentence)\n",
    "        synonym_sentence = synonym_sentence[1:]\n",
    "        new_sentence = synonym_sentence.capitalize()\n",
    "#         print(\"NEW SENTENCE: \" + new_sentence)\n",
    "        cntrl = 1\n",
    "        \n",
    "        sentence_value = valueList(synonym_sentence)\n",
    "        \n",
    "        total_value = 0\n",
    "        for value in sentence_value:\n",
    "            total_value += value\n",
    "            \n",
    "        if total_value <= sentence_sum+100 and total_value > sentence_sum:\n",
    "            gen_sentence_list.append(new_sentence)\n",
    "            \n",
    "        if len(gen_sentence_list) == 1:\n",
    "            break\n",
    "               \n",
    "    for i in gen_sentence_list:\n",
    "        print(i)   \n",
    "    \n",
    "generate_sentence()\n",
    "shutdownJVM()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}